{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfontanarosa/ground-platform/blob/notebooks/notebooks/generate_offline_imagery2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-process Ground imagery (2/2)\n",
        "\n",
        "This notebook converts normal GeoTIFFs into cloud optimized-GeoTIFFs (COGs) compatible with Google Maps Platform APIs and the Ground data collection platform Android app.\n",
        "\n",
        "We've affectionally dubbed these Maps-optimized COGs as \"MOGs\" for convenience and brevity. See [README.md](https://github.com/google/ground-android/blob/master/ground/src/main/java/com/google/android/ground/ui/map/gms/mog/README.md) in Android implementation for details.\n",
        "\n",
        "Be sure [Generate Ground offline imagery](https://colab.research.google.com/github/google/ground-platform/blob/master/notebooks/generate_offline_imagery1.ipynb) has been run and Earth Engine tasks have completed before running this notebook.\n",
        "\n",
        "By default, only new input images will be converted. GeoTIFF which already have a correspondign MOG will be skipped unless `OVERWRITE_EXISTING` is set `True`."
      ],
      "metadata": {
        "id": "MN0yiT1u74PH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Configuration"
      ],
      "metadata": {
        "id": "H1lIE8pBI1C5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required inputs"
      ],
      "metadata": {
        "id": "iLklRTCxI35n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_NAME=input('ID of Firebase project where GeoTIFFs are read and written: ') + \".appspot.com\""
      ],
      "metadata": {
        "id": "wqIeqxMEI5-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom paths\n",
        "\n",
        "The can be adjusted as needed."
      ],
      "metadata": {
        "id": "lTpntWE-JxHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PATH=\"raw-imagery/s2/2022\"\n",
        "DEST_PATH=\"offline-imagery/default\""
      ],
      "metadata": {
        "id": "O4yVrj-6JrBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other constants\n",
        "\n",
        "Only modify these if you know what you're doing!"
      ],
      "metadata": {
        "id": "FGXD1IEjJkto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "\n",
        "HI_RES_MOG_MIN_ZOOM=8\n",
        "HI_RES_MOG_MAX_ZOOM=14\n",
        "TILE_SIZE=256\n",
        "NODATA_VALUE=0\n",
        "OVERVIEW_FILENAME=\"overview.tif\"\n",
        "OVERWRITE_EXISTING=False\n",
        "\n",
        "SRC_PREFIX=f\"{SRC_PATH}/{HI_RES_MOG_MIN_ZOOM}\"\n",
        "OVERVIEW_TIFF_PATH=f\"{SRC_PREFIX}/{OVERVIEW_FILENAME}\"\n",
        "DEST_PREFIX=f\"{DEST_PATH}/{HI_RES_MOG_MIN_ZOOM}\"\n",
        "OVERVIEW_COG_PATH=f\"{DEST_PREFIX}/{OVERVIEW_FILENAME}\"\n",
        "\n",
        "# Constants\n",
        "TMP_FILENAME=\"temp.tif\"\n",
        "GCS_BROWSER_BASE_URL=\"https://console.cloud.google.com/storage/browser\"\n",
        "GCS_DETAILS_BASE_URL=\"https://console.cloud.google.com/storage/browser/_details\"\n",
        "EPSG_3857_MAX = pi * 6378137\n",
        "EPSG_3857_WORLD_BOUNDS=(-EPSG_3857_MAX, -EPSG_3857_MAX, EPSG_3857_MAX, EPSG_3857_MAX)"
      ],
      "metadata": {
        "id": "FFNaHNCUJpBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "uj_gNNC7Ahxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate user"
      ],
      "metadata": {
        "id": "4dXJ8YvyK40h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "xdxkoBhM0c75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install deps"
      ],
      "metadata": {
        "id": "proLU21CK1dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio rio-cogeo gdal"
      ],
      "metadata": {
        "id": "dXgnK9v3K3Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and vars"
      ],
      "metadata": {
        "id": "P8YlhMwZO2ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.windows import from_bounds\n",
        "from osgeo import gdal # https://gdal.org/api/python/osgeo.gdal.html\n",
        "import os\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import tempfile\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(BUCKET_NAME)"
      ],
      "metadata": {
        "id": "-VHrh342O1o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build MOGs\n"
      ],
      "metadata": {
        "id": "oWP2XrQOzu06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define functions"
      ],
      "metadata": {
        "id": "ibZtsecW20L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_size(path):\n",
        "  file_stats=os.stat(path)\n",
        "  print(f'{path}: {file_stats.st_size / (1024 * 1024):.2f} MB')\n",
        "\n",
        "def show_thumbnail(src_path):\n",
        "  with rasterio.open(src_path) as ds:\n",
        "    print(f'Profile: {ds.profile}')\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    show(ds.read(out_shape=(3, 512, 512)))\n",
        "\n",
        "def build_cog(src_path, dst_path):\n",
        "  \"\"\"Convert image to Maps Optimized GeoTIFF and upload to GCS.\"\"\"\n",
        "\n",
        "  gdal.UseExceptions()\n",
        "\n",
        "  # Open the input raster\n",
        "  src=gdal.Open(src_path)\n",
        "\n",
        "  # Open the output raster\n",
        "  ds=gdal.Translate(\n",
        "      destName=TMP_FILENAME,\n",
        "      srcDS=src,\n",
        "      format=\"COG\",\n",
        "      options=[\"GDAL_TIFF_INTERNAL_MASK=YES\"],\n",
        "      creationOptions=[\n",
        "          f\"BLOCKSIZE={TILE_SIZE}\",\n",
        "          \"BIGTIFF=NO\",\n",
        "          \"TILING_SCHEME=GoogleMapsCompatible\",\n",
        "          \"COMPRESS=JPEG\",\n",
        "          \"QUALITY=75\"\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # Close the output raster to flush buffer.\n",
        "  ds = None\n",
        "  tmp_ds = None\n",
        "\n",
        "  file_size = os.stat(TMP_FILENAME).st_size / (1024 * 1024)\n",
        "  print(f\"Uploading {file_size:.1f} MB to {dst_path}\")\n",
        "  bucket.blob(dst_path).upload_from_filename(TMP_FILENAME)"
      ],
      "metadata": {
        "id": "WH5iiIDx2ywe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build hi-res COGs"
      ],
      "metadata": {
        "id": "1y7pICte26lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Scanning {GCS_BROWSER_BASE_URL}/{BUCKET_NAME}/{SRC_PREFIX}\")\n",
        "src_blobs = storage_client.list_blobs(BUCKET_NAME, prefix=SRC_PREFIX)\n",
        "src_paths = [b.name for b in src_blobs if b.name.endswith(\".tif\")]\n",
        "\n",
        "print(f\"Building COGs from {len(src_paths)} GeoTIFFs\")\n",
        "print(src_paths)\n",
        "print(f\"Output: https://console.cloud.google.com/storage/browser/{BUCKET_NAME}/{DEST_PREFIX}\")\n",
        "\n",
        "for subpath in src_paths:\n",
        "  src_path=f\"/vsigs_streaming/{BUCKET_NAME}/{subpath}\"\n",
        "  dst_path=DEST_PREFIX + subpath[len(SRC_PREFIX):]\n",
        "  blob = storage.Blob(dst_path, bucket)\n",
        "  if (not OVERWRITE_EXISTING and blob.exists(storage_client)):\n",
        "    print(f\"{dst_path} exists, skipping.\")\n",
        "  else:\n",
        "    print(f\"Building {dst_path}\")\n",
        "    build_cog(\n",
        "        src_path=src_path,\n",
        "        dst_path=dst_path\n",
        "    )\n",
        "    show_size(TMP_FILENAME)\n",
        "    show_thumbnail(f\"/vsigs_streaming/{BUCKET_NAME}/{dst_path}\")\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "2JdD7hlEqTQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rebuild lo-res overview\n",
        "\n",
        "The overview COG includes a lo-res copy of all COGs in the destination bucket, with missing pixels set to NODATA."
      ],
      "metadata": {
        "id": "3I8QEJxY3EqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def downscale_profile(profile, factor):\n",
        "  transform = profile['transform']\n",
        "  new_profile = profile.copy()\n",
        "  new_transform = transform * transform.scale(\n",
        "    (profile['width'] / factor),\n",
        "    (profile['height'] / factor)\n",
        "  )\n",
        "  new_profile.update(transform=new_transform)\n",
        "  return new_profile\n",
        "\n",
        "def extend_profile_bounds(profile, xmin, ymin, xmax, ymax):\n",
        "  transform = profile['transform']\n",
        "  pixel_size_x, pixel_size_y = transform.a, -transform.e\n",
        "  new_transform = from_origin(xmin, ymax, pixel_size_x, pixel_size_y)\n",
        "\n",
        "  new_width = int((xmax - xmin) / pixel_size_x)\n",
        "  new_height = int((ymax - ymin) / pixel_size_y)\n",
        "\n",
        "  new_profile = profile.copy()\n",
        "  new_profile.update(\n",
        "      width=new_width,\n",
        "      height=new_height,\n",
        "      transform=new_transform,\n",
        "      tiled=True,\n",
        "      blockxsize=TILE_SIZE,\n",
        "      blockysize=TILE_SIZE,\n",
        "      nodata=NODATA_VALUE\n",
        "    )\n",
        "  return new_profile\n",
        "\n",
        "def build_overview_profile(src_path, xmin, ymin, xmax, ymax):\n",
        "  with rasterio.open(src_path) as src:\n",
        "    # Downscale one zoom level past smallest overview.\n",
        "    downscale_factor = src.overviews(1)[-1] * 2\n",
        "    downscaled_profile = downscale_profile(src.profile, downscale_factor)\n",
        "    return extend_profile_bounds(downscaled_profile, xmin, ymin, xmax, ymax), downscale_factor\n",
        "\n",
        "def write_canvas(dst, profile):\n",
        "  count = profile['count']\n",
        "  width = profile['width']\n",
        "  height = profile['height']\n",
        "  shape = (count, height, width)\n",
        "  dtype = profile['dtype']\n",
        "  dst.write(np.full(shape, NODATA_VALUE, dtype))\n",
        "\n",
        "def calculate_offsets(src, dst_profile, xmin, ymax):\n",
        "  pixel_size_x, pixel_size_y = dst_profile['transform'].a, -dst_profile['transform'].e\n",
        "  col = int((src.bounds.left - xmin) / pixel_size_x)\n",
        "  row = int((ymax - src.bounds.top) / pixel_size_y)\n",
        "  return col, row\n",
        "\n",
        "def downscale_and_merge(src, dst, downscale_factor, xmin, ymax, profile):\n",
        "  # Write the original data to the new raster at the correct location\n",
        "  downscaled_height = src.height / downscale_factor\n",
        "  downscaled_width = src.width / downscale_factor\n",
        "  data = src.read(\n",
        "    out_shape=(\n",
        "      src.count,\n",
        "      int(downscaled_height),\n",
        "      int(downscaled_width)\n",
        "    ),\n",
        "    resampling=Resampling.bilinear\n",
        "  )\n",
        "\n",
        "  # Calculate the offset to paste the original data in the new raster\n",
        "  col, row = calculate_offsets(src, profile, xmin, ymax)\n",
        "\n",
        "  # Update the window in the new raster to match the original raster\n",
        "  dst_window = rasterio.windows.Window(col, row, downscaled_width, downscaled_height)\n",
        "\n",
        "  dst.write(data, window=dst_window)\n",
        "\n",
        "def build_overview(input_paths, output_path):\n",
        "  xmin, ymin, xmax, ymax = EPSG_3857_WORLD_BOUNDS\n",
        "  profile, downscale_factor = build_overview_profile(input_paths[0], xmin, ymin, xmax, ymax)\n",
        "\n",
        "  with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "    write_canvas(dst, profile)\n",
        "\n",
        "    for idx, input_path in enumerate(input_paths):\n",
        "      print(f\"Processing image {idx} of {len(input_paths)}\")\n",
        "      with rasterio.open(input_path) as src:\n",
        "        downscale_and_merge(src, dst, downscale_factor, xmin, ymax, profile)\n",
        "\n",
        "src_blobs = storage_client.list_blobs(BUCKET_NAME, prefix=DEST_PREFIX)\n",
        "print(BUCKET_NAME)\n",
        "print(DEST_PREFIX)\n",
        "paths = [x.name for x in src_blobs if '/world' not in x.name]\n",
        "print(f'/vsigs_streaming/{BUCKET_NAME}/')\n",
        "print(paths)\n",
        "input_paths = [f'/vsigs_streaming/{BUCKET_NAME}/{fp}' for fp in paths]\n",
        "tmpdir = tempfile.gettempdir()\n",
        "overview_tmp_path = os.path.join(tmpdir, OVERVIEW_FILENAME)\n",
        "\n",
        "print(input_paths)\n",
        "build_overview(input_paths, overview_tmp_path)\n",
        "\n",
        "# Build COG and upload to GCS.\n",
        "build_cog(\n",
        "    src_path=overview_tmp_path,\n",
        "    dst_path=f\"{DEST_PREFIX}/{OVERVIEW_FILENAME}\"\n",
        ")\n",
        "show_size(overview_tmp_path)\n",
        "show_thumbnail(\n",
        "    f\"/vsigs_streaming/{BUCKET_NAME}/{DEST_PREFIX}/{OVERVIEW_FILENAME}\")"
      ],
      "metadata": {
        "id": "5jUBkFLdPDvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}